{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6cf596b3",
   "metadata": {},
   "source": [
    "Установка и импорт библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc6f81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install torch torchvision torchaudio matplotlib segmentation-models-pytorch albumentations timm tqdm imagehash\n",
    "import segmentation_models_pytorch.losses as smp_losses\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import segmentation_models_pytorch as smp\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import imagehash\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import time\n",
    "import random\n",
    "import timm\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de541f43",
   "metadata": {},
   "source": [
    "Инициализация путей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49193a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DATASET_NAME = \"camvid-dataset\"\n",
    "\n",
    "X_TRAIN_DIR = f\"{DATASET_NAME}/Train\"\n",
    "Y_TRAIN_DIR = f\"{DATASET_NAME}/Trainannot\"\n",
    "\n",
    "X_VALID_DIR = f\"{DATASET_NAME}/Validation\"\n",
    "Y_VALID_DIR = f\"{DATASET_NAME}/Validationannot\"\n",
    "\n",
    "X_TEST_DIR = f\"{DATASET_NAME}/Test\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f494db75",
   "metadata": {},
   "source": [
    "Гиперпараметры\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c6e754",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS =50\n",
    "BATCH_SIZE = 8\n",
    "LEARNING_RATE = 0.001\n",
    "WEIGHT_DECAY = 0\n",
    "ENCODER_NAME = \"50 эпох 0 веса  0.001 самое новое\"\n",
    "ENCODER_WEIGHTS = \"imagenet\"\n",
    "NUM_CLASSES = 1\n",
    "IMAGE_SIZE = 512\n",
    "TARGET_COLOR = (0, 255, 255) \n",
    "MODEL_SAVE_PATH = f\"models/{ENCODER_NAME}_best_unet.pth\"\n",
    "GRAF_PATH = f\"graf/{ENCODER_NAME}_graf.pth\"\n",
    "WHEEL_COLOR = (0, 255, 255)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224adb73",
   "metadata": {},
   "source": [
    "Генератор синтетических кругов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af85b14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_circle_image(width=512, height=384):\n",
    "    image = np.zeros((height, width, 3), dtype=np.uint8)\n",
    "    mask = np.zeros((height, width, 3), dtype=np.uint8)\n",
    "    num_circles = np.random.randint(1, 6)\n",
    "    for _ in range(num_circles):\n",
    "        center = (np.random.randint(0, width), np.random.randint(0, height))\n",
    "        radius = np.random.randint(30, 150)\n",
    "        color = tuple(np.random.randint(0, 256, size=3))\n",
    "        cv2.circle(image, center, radius, color, -1)\n",
    "        cv2.circle(mask, center, radius, (0, 255, 255), -1)\n",
    "    noise = np.random.normal(0, 10, (height, width, 3)).astype(np.uint8)\n",
    "    image = cv2.add(image, noise)\n",
    "    return image, mask\n",
    "\n",
    "def generate_dataset(num_train=1000, num_val=200):\n",
    "    os.makedirs(X_TRAIN_DIR, exist_ok=True)\n",
    "    os.makedirs(Y_TRAIN_DIR, exist_ok=True)\n",
    "    os.makedirs(X_VALID_DIR, exist_ok=True)\n",
    "    os.makedirs(Y_VALID_DIR, exist_ok=True)\n",
    "    for i in range(num_train):\n",
    "        img, mask = generate_circle_image()\n",
    "        cv2.imwrite(f\"{X_TRAIN_DIR}/train_{i:04d}.png\", img)\n",
    "        cv2.imwrite(f\"{Y_TRAIN_DIR}/train_{i:04d}.png\", mask)\n",
    "    for i in range(num_val):\n",
    "        img, mask = generate_circle_image()\n",
    "        cv2.imwrite(f\"{X_VALID_DIR}/val_{i:04d}.png\", img)\n",
    "        cv2.imwrite(f\"{Y_VALID_DIR}/val_{i:04d}.png\", mask)\n",
    "    print(\"готово\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851c55c8",
   "metadata": {},
   "source": [
    "хаф Преобразование"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ef1f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def show_hough_filled(img_bgr, circles,\n",
    "                      fill_color=(0, 0, 255),\n",
    "                      alpha=0.35):\n",
    "    overlay = img_bgr.copy()\n",
    "    output  = img_bgr.copy()\n",
    "\n",
    "    if circles is not None:\n",
    "        for x, y, r in circles.astype(int):\n",
    "            cv2.circle(overlay, (x, y), r, fill_color, -1)\n",
    "            cv2.circle(output,  (x, y), r, fill_color,  2)\n",
    "            cv2.circle(output,  (x, y), 2, (0, 255, 0), -1)\n",
    "\n",
    "    output = cv2.addWeighted(overlay, alpha, output, 1 - alpha, 0)\n",
    "    return output\n",
    "\n",
    "\n",
    "for fname in tqdm(sorted(os.listdir(X_TEST_DIR))):\n",
    "    if not fname.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "        continue\n",
    "\n",
    "    path = os.path.join(X_TEST_DIR, fname)\n",
    "    img_bgr = cv2.imread(path)\n",
    "\n",
    "    gray = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.medianBlur(gray, 5)\n",
    "\n",
    "    circles = cv2.HoughCircles(\n",
    "        gray, cv2.HOUGH_GRADIENT,\n",
    "        dp=1.2,\n",
    "        minDist=30,\n",
    "        param1=400,\n",
    "        param2=40,\n",
    "        minRadius=15, maxRadius=200)\n",
    "\n",
    "    vis = show_hough_filled(\n",
    "        img_bgr,\n",
    "        circles[0] if circles is not None else None,\n",
    "        fill_color=(0, 0, 255),\n",
    "        alpha=0.35)\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.imshow(cv2.cvtColor(vis, cv2.COLOR_BGR2RGB))\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91cbaa95",
   "metadata": {},
   "source": [
    "даталоудер"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c529c540",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WheelDataset(Dataset):\n",
    "    def __init__(self, images_dir, masks_dir, transform=None, target_color=(0, 255, 255)):\n",
    "        self.images_dir = images_dir\n",
    "        self.masks_dir = masks_dir\n",
    "        self.transform = transform\n",
    "        self.target_color = np.array(target_color)\n",
    "\n",
    "        self.images_fps = sorted([\n",
    "            os.path.join(images_dir, fname)\n",
    "            for fname in os.listdir(images_dir)\n",
    "            if fname.lower().endswith(('.jpg', '.jpeg', '.png'))\n",
    "        ])\n",
    "\n",
    "        self.masks_fps = [\n",
    "            os.path.join(masks_dir, os.path.basename(img).rsplit('.', 1)[0] + '.png')\n",
    "            for img in self.images_fps\n",
    "        ]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images_fps)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = cv2.imread(self.images_fps[idx])\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        mask_path = self.masks_fps[idx]\n",
    "        if os.path.exists(mask_path):\n",
    "            mask = cv2.imread(mask_path)\n",
    "            binary_mask = np.all(mask == self.target_color, axis=-1).astype('float32')\n",
    "        else:\n",
    "            binary_mask = np.zeros(image.shape[:2], dtype='float32')\n",
    "\n",
    "\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image, mask=binary_mask)\n",
    "            image = augmented['image']\n",
    "            binary_mask = augmented['mask'].unsqueeze(0)\n",
    "\n",
    "        return image, binary_mask\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4642867b",
   "metadata": {},
   "source": [
    "аугументация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1de50b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = A.Compose([\n",
    "    A.Resize(256, 256),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.RandomBrightnessContrast(p=0.5),\n",
    "    A.GaussNoise(p=0.3),\n",
    "    A.CoarseDropout(max_holes=8, max_height=32, max_width=32, p=0.5),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "\n",
    "val_transform = A.Compose([\n",
    "    A.Resize(256, 256),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2()\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f9b0b7",
   "metadata": {},
   "source": [
    "Загружаем батчи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ec3268",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    WheelDataset(X_TRAIN_DIR, Y_TRAIN_DIR, train_transform, WHEEL_COLOR),\n",
    "    batch_size=BATCH_SIZE, shuffle=True, num_workers=0\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    WheelDataset(X_VALID_DIR, Y_VALID_DIR, val_transform, WHEEL_COLOR),\n",
    "    batch_size=BATCH_SIZE, shuffle=False, num_workers=0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4629a8",
   "metadata": {},
   "source": [
    "dice метрика"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda08fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self, smooth=1.0):\n",
    "        super().__init__()\n",
    "        self.smooth = smooth\n",
    "\n",
    "    def forward(self, preds, targets):\n",
    "        preds = torch.sigmoid(preds)\n",
    "        intersection = (preds * targets).sum()\n",
    "        dice = (2.0 * intersection + self.smooth) / (preds.sum() + targets.sum() + self.smooth)\n",
    "        return 1.0 - dice\n",
    "\n",
    "def dice_score(preds, targets, threshold=0.5):\n",
    "    preds = (torch.sigmoid(preds) > threshold)\n",
    "    targets = (targets > threshold)\n",
    "    intersection = (preds & targets).float().sum()\n",
    "    return (2.0 * intersection) / (preds.sum() + targets.sum() + 1e-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041c6a56",
   "metadata": {},
   "source": [
    "Сама архетектура и энкодер"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbece694",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super().__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_ch, out_ch, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "\n",
    "class AttentionGate(nn.Module):\n",
    "    def __init__(self, g_channels, x_channels, inter_channels):\n",
    "        super().__init__()\n",
    "        self.W_g = nn.Conv2d(g_channels, inter_channels, kernel_size=1)\n",
    "        self.W_x = nn.Conv2d(x_channels, inter_channels, kernel_size=1)\n",
    "        self.psi = nn.Conv2d(inter_channels, 1, kernel_size=1)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, g, x):\n",
    "        g1 = self.W_g(g)\n",
    "        x1 = self.W_x(x)\n",
    "        psi = self.relu(g1 + x1)\n",
    "        psi = self.sigmoid(self.psi(psi))\n",
    "        return x * psi\n",
    "\n",
    "class UNetEfficientNetB4(nn.Module):\n",
    "    def __init__(self, num_classes=1):\n",
    "        super().__init__()\n",
    "        self.encoder = timm.create_model(\"efficientnet_b4\", pretrained=True, features_only=True)\n",
    "        enc_channels = self.encoder.feature_info.channels()\n",
    "        \n",
    "        self.center = ConvBlock(enc_channels[-1], 512)\n",
    "        \n",
    "        self.attn4 = AttentionGate(256, enc_channels[-2], enc_channels[-2] // 2)\n",
    "        self.attn3 = AttentionGate(128, enc_channels[-3], enc_channels[-3] // 2)\n",
    "        self.attn2 = AttentionGate(64, enc_channels[-4], enc_channels[-4] // 2)\n",
    "        self.attn1 = AttentionGate(32, enc_channels[-5], enc_channels[-5] // 2)\n",
    "        \n",
    "        self.up4 = self._up_block(512, 256)\n",
    "        self.up3 = self._up_block(256, 128)\n",
    "        self.up2 = self._up_block(128, 64)\n",
    "        self.up1 = self._up_block(64, 32)\n",
    "        \n",
    "        self.conv_block4 = ConvBlock(256 + enc_channels[-2], 256)\n",
    "        self.conv_block3 = ConvBlock(128 + enc_channels[-3], 128)\n",
    "        self.conv_block2 = ConvBlock(64 + enc_channels[-4], 64)\n",
    "        self.conv_block1 = ConvBlock(32 + enc_channels[-5], 32)\n",
    "        \n",
    "        self.final_conv = nn.Conv2d(32, num_classes, kernel_size=1)\n",
    "\n",
    "    def _up_block(self, in_ch, out_ch):\n",
    "        return nn.Sequential(\n",
    "            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=False),\n",
    "            nn.Conv2d(in_ch, out_ch, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        input_size = x.shape[2:]\n",
    "        features = self.encoder(x)\n",
    "        \n",
    "        x = self.center(features[-1])\n",
    "        \n",
    "        x = self.up4(x)\n",
    "        attn4 = self.attn4(x, features[-2])\n",
    "        x = torch.cat([x, attn4], dim=1)\n",
    "        x = self.conv_block4(x)\n",
    "        \n",
    "        x = self.up3(x)\n",
    "        attn3 = self.attn3(x, features[-3])\n",
    "        x = torch.cat([x, attn3], dim=1)\n",
    "        x = self.conv_block3(x)\n",
    "        \n",
    "        x = self.up2(x)\n",
    "        attn2 = self.attn2(x, features[-4])\n",
    "        x = torch.cat([x, attn2], dim=1)\n",
    "        x = self.conv_block2(x)\n",
    "        \n",
    "        x = self.up1(x)\n",
    "        attn1 = self.attn1(x, features[-5])\n",
    "        x = torch.cat([x, attn1], dim=1)\n",
    "        x = self.conv_block1(x)\n",
    "        \n",
    "        x = self.final_conv(x)\n",
    "        x = F.interpolate(x, size=input_size, mode='bilinear', align_corners=False)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144b3c85",
   "metadata": {},
   "source": [
    "Инициализация модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3042b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNetEfficientNetB4(num_classes=NUM_CLASSES).cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550555db",
   "metadata": {},
   "source": [
    "обучение УБРАТЬ КОММАНТАРИЙ ДЛЯ ЗАПУСКА"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2848c7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=3)\n",
    "dice_loss = DiceLoss()\n",
    "best_val_dice = 0\n",
    "best_val_loss = float('inf')\n",
    "train_losses, val_losses = [], []\n",
    "train_dices, val_dices = [], []\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(1, NUM_EPOCHS + 1):\n",
    "    epoch_start = time.time()\n",
    "    print(f\"\\nЭпоха {epoch}/{NUM_EPOCHS}\")\n",
    "    model.train()\n",
    "    total_loss, total_dice = 0, 0\n",
    "    for images, masks in tqdm(train_loader):\n",
    "        images, masks = images.cuda(), masks.cuda()\n",
    "        preds = model(images)\n",
    "        loss = dice_loss(preds, masks)\n",
    "        dsc = dice_score(preds, masks)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        total_dice += dsc.item()\n",
    "    avg_train_loss = total_loss / len(train_loader)\n",
    "    avg_train_dice = total_dice / len(train_loader)\n",
    "    train_losses.append(avg_train_loss)\n",
    "    train_dices.append(avg_train_dice)\n",
    "    print(f\"Тренеровочный Loss: {avg_train_loss:.4f}, Dice: {avg_train_dice:.4f}\")\n",
    "\n",
    "    model.eval()\n",
    "    val_loss, val_dice = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for images, masks in val_loader:\n",
    "            images, masks = images.cuda(), masks.cuda()\n",
    "            preds = model(images)\n",
    "            loss = dice_loss(preds, masks)\n",
    "            dsc = dice_score(preds, masks)\n",
    "            val_loss += loss.item()\n",
    "            val_dice += dsc.item()\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    avg_val_dice = val_dice / len(val_loader)\n",
    "    val_losses.append(avg_val_loss)\n",
    "    val_dices.append(avg_val_dice)\n",
    "    print(f\"Проверочный   Loss: {avg_val_loss:.4f}, Dice: {avg_val_dice:.4f}\")\n",
    "\n",
    "    scheduler.step(avg_val_dice)\n",
    "    epoch_time = time.time() - epoch_start\n",
    "    eta = epoch_time * (NUM_EPOCHS - epoch)\n",
    "    print(f\"Время: {epoch_time:.1f}s | Осталость: {eta/60:.1f} min\")\n",
    "\n",
    "    torch.save({\n",
    "    'train_losses': train_losses,\n",
    "    'val_losses': val_losses,\n",
    "    'train_dices': train_dices,\n",
    "    'val_dices': val_dices\n",
    "    }, GRAF_PATH)\n",
    "\n",
    "    if avg_val_dice > best_val_dice:\n",
    "        best_val_dice = avg_val_dice\n",
    "        torch.save(model.state_dict(), MODEL_SAVE_PATH)\n",
    "        print(\"Эту сохранил\")\n",
    "\n",
    "\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "print(f\"\\nЗавершил {total_time/60:.2f} минут\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9527644",
   "metadata": {},
   "source": [
    "Царь график"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476008db",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "GRAF_PATH = r\"graf\\50 эпох 0 веса  0.001 самое новое_graf.pth\"\n",
    "\n",
    "data = torch.load(GRAF_PATH)\n",
    "\n",
    "train_losses = data['train_losses']\n",
    "val_losses = data['val_losses']\n",
    "train_dices = data['train_dices']\n",
    "val_dices = data['val_dices']\n",
    "print(f\"Последние значения:\")\n",
    "print(f\"Train Loss: {train_losses[-1]}\")\n",
    "print(f\"Val Loss:   {val_losses[-1]}\")\n",
    "print(f\"Train Dice: {train_dices[-1]}\")\n",
    "print(f\"Val Dice:   {val_dices[-1]}\")\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses, label='Обучение')\n",
    "plt.plot(val_losses, label='Валидация')\n",
    "plt.title('Функция Loss по эпохам')\n",
    "plt.xlabel('Эпоха')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_dices, label='Обучение')\n",
    "plt.plot(val_dices, label='Валидация')\n",
    "plt.title('Dice по эпохам')\n",
    "plt.xlabel('Эпоха')\n",
    "plt.ylabel('Dice')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e494c0a",
   "metadata": {},
   "source": [
    "Предиктим"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a195d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model.load_state_dict(torch.load(MODEL_SAVE_PATH))\n",
    "model.eval()\n",
    "\n",
    "transform = A.Compose([\n",
    "    A.Resize(256, 256),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "def visualize_prediction(img_path):\n",
    "    orig_img = np.array(Image.open(img_path).convert(\"RGB\"))\n",
    "\n",
    "    tensor = transform(image=orig_img)['image'].unsqueeze(0).cuda()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pred_mask = model(tensor)\n",
    "        pred_mask = (torch.sigmoid(pred_mask).cpu().squeeze().numpy() > 0.6).astype(np.uint8)\n",
    "        pred_mask_resized = cv2.resize(pred_mask, (orig_img.shape[1], orig_img.shape[0]))\n",
    "\n",
    "    overlay_img = orig_img.copy()\n",
    "    overlay_img[pred_mask_resized == 1] = [255, 0, 0]\n",
    "\n",
    "    overlay_img = cv2.addWeighted(orig_img, 0.5, overlay_img, 0.5, 0)\n",
    "\n",
    "    plt.figure(figsize=(12, 4))\n",
    "\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(orig_img)\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(pred_mask_resized, cmap=\"gray\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(overlay_img)\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "for img_file in sorted(os.listdir(X_TEST_DIR))[:20]:\n",
    "    if img_file.lower().endswith((\".png\", \".jpg\", \".jpeg\")):\n",
    "        img_path = os.path.join(X_TEST_DIR, img_file)\n",
    "        visualize_prediction(img_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
